# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EpS15O33rvyCP44WGuSjstGqtLPr3nD6
"""

# Import necessary libraries
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout
# Load Dataset
car_crashes = sns.load_dataset('car_crashes')

# Explore the dataset
print(car_crashes.head())
print(car_crashes.info())
print(car_crashes.describe())
# Pairplot to visualize relationships between features
sns.pairplot(car_crashes)
plt.show()
# Heatmap to show correlation between features
plt.figure(figsize=(10, 6))
numeric_car_crashes = car_crashes.select_dtypes(include=[np.number])
sns.heatmap(numeric_car_crashes.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()
# Distribution of 'total' car crashes
plt.figure(figsize=(10, 6))
sns.histplot(car_crashes['total'], bins=20, kde=True)
plt.title('Distribution of Total Car Crashes')
plt.show()
# Box plot to visualize outliers in the features
plt.figure(figsize=(10, 6))
sns.boxplot(data=car_crashes.drop(columns=['abbrev']))
plt.title('Boxplot of Features')
plt.xticks(rotation=45)
plt.show()
# Scatter plot for 'speeding' vs 'total' car crashes
plt.figure(figsize=(10, 6))
sns.scatterplot(x='speeding', y='total', data=car_crashes)
plt.title('Speeding vs Total Car Crashes')
plt.show()
# Checking for missing values
print(car_crashes.isnull().sum())
# Feature selection and engineering
features = car_crashes[['speeding', 'alcohol', 'not_distracted', 'no_previous', 'ins_premium', 'ins_losses']]
target = car_crashes['total']

print(features.head())
print(target.head())
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
print("X_train:", X_train.shape)
print("X_test:", X_test.shape)
print("y_train:", y_train.shape)
print("y_test:", y_test.shape)
# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Model 1: Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)
lr_pred = lr_model.predict(X_test_scaled)
print("Linear Regression MSE:", mean_squared_error(y_test, lr_pred))
print("Linear Regression R2 Score:", r2_score(y_test, lr_pred))
print("Linear Regression Coefficients:", lr_model.coef_)
# Model 2: Random Forest
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
print("Random Forest MSE:", mean_squared_error(y_test, rf_pred))
print("Random Forest R2 Score:", r2_score(y_test, rf_pred))
print("Random Forest Feature Importances:", rf_model.feature_importances_)
# Model 3: Gradient Boosting
gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)
gb_pred = gb_model.predict(X_test)
print("Gradient Boosting MSE:", mean_squared_error(y_test, gb_pred))
print("Gradient Boosting R2 Score:", r2_score(y_test, gb_pred))
print("Gradient Boosting Feature Importances:", gb_model.feature_importances_)
# Model 4: Convolutional Neural Network (CNN)
X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

cnn_model = Sequential([
    Conv1D(64, kernel_size=2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    Dropout(0.5),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(1)
])

cnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
cnn_model.fit(X_train_cnn, y_train, epochs=50, batch_size=10, verbose=1)
cnn_pred = cnn_model.predict(X_test_cnn)
# Evaluation
# Evaluation for Linear Regression
lr_mse = mean_squared_error(y_test, lr_pred)
lr_r2 = r2_score(y_test, lr_pred)
print(f"Linear Regression - Mean Squared Error: {lr_mse}, R^2 Score: {lr_r2}")

# Evaluation for Random Forest
rf_mse = mean_squared_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)
print(f"Random Forest - Mean Squared Error: {rf_mse}, R^2 Score: {rf_r2}")

# Evaluation for Gradient Boosting
gb_mse = mean_squared_error(y_test, gb_pred)
gb_r2 = r2_score(y_test, gb_pred)
print(f"Gradient Boosting - Mean Squared Error: {gb_mse}, R^2 Score: {gb_r2}")

# Evaluation for CNN
cnn_mse = mean_squared_error(y_test, cnn_pred)
cnn_r2 = r2_score(y_test, cnn_pred)
print(f"CNN - Mean Squared Error: {cnn_mse}, R^2 Score: {cnn_r2}")
# Scatter plot for Actual vs Predicted for each model
plt.figure(figsize=(15, 10))

plt.subplot(2, 2, 1)
plt.scatter(y_test, lr_pred, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Linear Regression - Actual vs Predicted')

plt.subplot(2, 2, 2)
plt.scatter(y_test, rf_pred, color='green')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Random Forest - Actual vs Predicted')

plt.subplot(2, 2, 3)
plt.scatter(y_test, gb_pred, color='red')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Gradient Boosting - Actual vs Predicted')

plt.subplot(2, 2, 4)
plt.scatter(y_test, cnn_pred, color='purple')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('CNN - Actual vs Predicted')

plt.tight_layout()
plt.show()
# Bar plot for comparison of MSE and R^2 Score
models = ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'CNN']
mse_values = [lr_mse, rf_mse, gb_mse, cnn_mse]
r2_values = [lr_r2, rf_r2, gb_r2, cnn_r2]

plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
sns.barplot(x=models, y=mse_values)
plt.title('Mean Squared Error Comparison')
plt.ylabel('MSE')

plt.subplot(1, 2, 2)
sns.barplot(x=models, y=r2_values)
plt.title('R^2 Score Comparison')
plt.ylabel('R^2 Score')

plt.tight_layout()
plt.show()